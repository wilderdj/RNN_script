{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 62 characters\n"
     ]
    }
   ],
   "source": [
    "textfile = (\"C:/Users/wilde/Downloads/Python_Certification/house_script.txt\")\n",
    "data = open(textfile, 'rb').read().decode(encoding='utf-8')\n",
    "print ('Length of text: {} characters'.format(len(textfile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rebecca riding bus and then running into a school. Meets up with Melanie] Melanie: Why are you late? Rebecca: You’re not going to like the answer. Melanie: I already know the answer. Rebecca: I missed the bus. Melanie: I don’t doubt it, no bus stops\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(data[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(data))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(data):\n",
    "  return np.array([char2idx[c] for c in data])\n",
    "\n",
    "text_as_int = text_to_int(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: [Rebecca riding\n",
      "Encoded: [47 40 53 50 53 51 51 49  0 66 57 52 57 62 55]\n"
     ]
    }
   ],
   "source": [
    "# lets look at how part of our text is encoded\n",
    "print(\"Text:\", data[:15])\n",
    "print(\"Encoded:\", text_to_int(data[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rebecca riding\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "  try:\n",
    "    ints = ints.numpy()\n",
    "  except:\n",
    "    pass\n",
    "  return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(data)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "[Rebecca riding bus and then running into a school. Meets up with Melanie] Melanie: Why are you late\n",
      "\n",
      "OUTPUT\n",
      "Rebecca riding bus and then running into a school. Meets up with Melanie] Melanie: Why are you late?\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      " Rebecca: You’re not going to like the answer. Melanie: I already know the answer. Rebecca: I missed\n",
      "\n",
      "OUTPUT\n",
      "Rebecca: You’re not going to like the answer. Melanie: I already know the answer. Rebecca: I missed \n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "  print(\"\\n\\nEXAMPLE\\n\")\n",
    "  print(\"INPUT\")\n",
    "  print(int_to_text(x))\n",
    "  print(\"\\nOUTPUT\")\n",
    "  print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data1 = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           20736     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 81)            83025     \n",
      "=================================================================\n",
      "Total params: 5,350,737\n",
      "Trainable params: 5,350,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 81) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data1.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 7.95843545e-04 -3.62348044e-03 -2.10069958e-03 ...  1.14218204e-03\n",
      "    3.13831260e-05  1.44786853e-03]\n",
      "  [ 2.99980864e-03 -4.65280795e-03 -5.43536525e-03 ...  4.02377266e-03\n",
      "   -7.22963596e-05 -3.20299226e-03]\n",
      "  [-3.47720133e-03 -2.42220471e-03 -3.89663130e-03 ...  7.25093298e-04\n",
      "    7.99313560e-03 -6.91624964e-03]\n",
      "  ...\n",
      "  [-3.92452069e-03  3.18783708e-03  7.39302114e-03 ...  2.04230286e-03\n",
      "   -3.64290783e-04 -4.62318677e-03]\n",
      "  [ 2.35126214e-03 -3.02760862e-04  7.53474073e-04 ...  2.35056155e-03\n",
      "   -4.64338902e-03 -8.32307246e-03]\n",
      "  [ 3.06645408e-03  2.19218596e-03  6.70239097e-03 ...  4.80801146e-03\n",
      "   -6.46725995e-03 -6.21082634e-03]]\n",
      "\n",
      " [[ 1.84395595e-03  1.35494908e-03  6.16411585e-03 ...  2.76800175e-03\n",
      "   -2.45373906e-03  8.95111531e-04]\n",
      "  [-4.60220873e-03  3.13576311e-03  4.66461666e-03 ...  9.40705766e-04\n",
      "    1.78144418e-03  6.42099534e-04]\n",
      "  [-4.93489392e-03  3.83698614e-03 -1.85017334e-03 ... -2.41430919e-03\n",
      "    3.94137483e-03  7.12798268e-04]\n",
      "  ...\n",
      "  [ 4.06944379e-03 -9.97529551e-03 -2.48049246e-03 ... -4.48081503e-03\n",
      "   -1.85546582e-03 -9.25862789e-03]\n",
      "  [ 4.64996463e-03 -4.28785011e-03  3.99434287e-03 ...  4.13966831e-04\n",
      "   -4.57236031e-03 -4.09770804e-03]\n",
      "  [ 3.89430602e-03  1.54798641e-03 -4.38225572e-04 ... -1.18689379e-04\n",
      "   -5.11504710e-03 -3.38902976e-03]]\n",
      "\n",
      " [[-3.13536904e-04  1.26417517e-03  2.91724689e-03 ... -1.43170136e-03\n",
      "    6.87676203e-03  1.83196901e-03]\n",
      "  [ 1.19861879e-03 -8.71520315e-04 -1.81017327e-03 ...  1.34197017e-03\n",
      "    4.33441997e-03 -2.59694573e-03]\n",
      "  [-1.33364322e-03 -3.88270058e-03 -3.02410073e-04 ... -4.56160959e-03\n",
      "    4.70718648e-03 -2.76350230e-03]\n",
      "  ...\n",
      "  [ 1.56891067e-04  1.35779120e-02 -1.31479790e-02 ... -5.70202246e-03\n",
      "    4.00599744e-03 -1.18953250e-02]\n",
      "  [ 4.68606711e-04  1.12912748e-02 -1.28102573e-02 ... -1.31309603e-03\n",
      "    2.26931204e-03 -1.19601311e-02]\n",
      "  [-6.89650048e-03  1.31195746e-02 -1.05588157e-02 ... -1.90600136e-03\n",
      "    5.69087733e-03 -7.85382092e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.28267412e-03 -5.29186707e-03 -4.32336470e-04 ... -2.98959808e-03\n",
      "    4.86019999e-05 -5.92595525e-03]\n",
      "  [ 3.60856345e-03 -3.83399939e-03  6.20718754e-04 ... -1.45425380e-03\n",
      "    7.10555213e-03 -2.45946296e-03]\n",
      "  [ 4.23757266e-03 -7.12768128e-03 -3.85538908e-04 ... -2.23597651e-03\n",
      "    2.91898241e-03 -4.77805175e-03]\n",
      "  ...\n",
      "  [ 6.22111093e-03 -3.71423061e-03 -4.49510245e-03 ... -6.64755562e-03\n",
      "    6.00363966e-03 -5.10662794e-03]\n",
      "  [ 5.94285224e-03 -3.20197688e-03 -6.04803255e-03 ... -2.26046890e-03\n",
      "    2.82576354e-03 -7.84077682e-03]\n",
      "  [-2.10690941e-03 -4.17960575e-04 -3.17476154e-03 ... -4.37228568e-03\n",
      "    8.86733085e-03 -9.96869337e-03]]\n",
      "\n",
      " [[ 1.58238341e-03 -1.93433487e-03 -3.38760903e-03 ...  2.74270400e-03\n",
      "   -9.99202137e-04 -4.34926851e-03]\n",
      "  [-5.37704071e-03  1.56740402e-03 -1.02944206e-04 ...  9.53034032e-03\n",
      "   -3.44737968e-03 -3.96642927e-03]\n",
      "  [ 1.28817349e-03 -2.67611793e-03 -6.02260698e-03 ...  6.89062895e-03\n",
      "   -6.64470997e-03 -8.73655267e-03]\n",
      "  ...\n",
      "  [-2.12748861e-03  8.62824265e-03  7.19778705e-04 ...  2.12169904e-03\n",
      "    7.55486265e-03  7.04955542e-04]\n",
      "  [-7.33541418e-03  9.68589261e-03  3.45539697e-03 ...  1.21897343e-03\n",
      "    1.37557145e-02 -2.31492985e-03]\n",
      "  [-1.08737862e-02  1.17574446e-02  3.14152171e-03 ...  1.81091030e-03\n",
      "    1.43362582e-02  5.34538412e-04]]\n",
      "\n",
      " [[ 1.50373369e-03 -5.01690293e-03 -7.88765086e-04 ... -2.17442052e-03\n",
      "   -2.19062204e-03 -4.62459773e-03]\n",
      "  [ 3.80376843e-03 -2.39475956e-03  4.70115524e-03 ...  1.41761126e-03\n",
      "   -3.90412938e-03 -2.18951656e-03]\n",
      "  [-2.45137140e-03 -1.01045845e-03  4.83397860e-03 ... -1.23082870e-03\n",
      "    4.61612456e-03 -6.13233680e-03]\n",
      "  ...\n",
      "  [ 4.72772261e-03  1.85349770e-03 -1.08320080e-02 ... -5.84443426e-03\n",
      "    6.34464156e-03 -1.43222259e-02]\n",
      "  [ 4.27917019e-03 -7.88650475e-04 -8.80516693e-03 ... -7.31372880e-03\n",
      "    6.72264071e-03 -9.11750458e-03]\n",
      "  [ 3.97162465e-03 -8.23592767e-04 -1.06018055e-02 ... -1.97694846e-03\n",
      "    4.61011427e-03 -1.03394222e-02]]], shape=(64, 100, 81), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 7.9584355e-04 -3.6234804e-03 -2.1006996e-03 ...  1.1421820e-03\n",
      "   3.1383126e-05  1.4478685e-03]\n",
      " [ 2.9998086e-03 -4.6528080e-03 -5.4353653e-03 ...  4.0237727e-03\n",
      "  -7.2296360e-05 -3.2029923e-03]\n",
      " [-3.4772013e-03 -2.4222047e-03 -3.8966313e-03 ...  7.2509330e-04\n",
      "   7.9931356e-03 -6.9162496e-03]\n",
      " ...\n",
      " [-3.9245207e-03  3.1878371e-03  7.3930211e-03 ...  2.0423029e-03\n",
      "  -3.6429078e-04 -4.6231868e-03]\n",
      " [ 2.3512621e-03 -3.0276086e-04  7.5347407e-04 ...  2.3505616e-03\n",
      "  -4.6433890e-03 -8.3230725e-03]\n",
      " [ 3.0664541e-03  2.1921860e-03  6.7023910e-03 ...  4.8080115e-03\n",
      "  -6.4672600e-03 -6.2108263e-03]], shape=(100, 81), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# lets examine one prediction\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n",
    "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "tf.Tensor(\n",
      "[ 7.9584355e-04 -3.6234804e-03 -2.1006996e-03  1.1938311e-03\n",
      "  2.4589216e-03 -4.2584562e-04  1.4638313e-03  5.2954094e-04\n",
      " -1.3516761e-03 -5.3014033e-03  7.4480437e-03  2.4958833e-03\n",
      "  1.9846698e-03 -1.1027359e-03 -5.1027369e-03  2.4702069e-03\n",
      "  4.9059279e-03 -4.1747792e-03 -4.0667178e-03  4.8114164e-03\n",
      " -3.0620345e-03 -7.5250177e-04  4.7471281e-04  2.2397088e-03\n",
      "  4.0121530e-03  6.0209753e-03  1.7075054e-03 -2.7557034e-03\n",
      " -3.9565428e-03  8.6266664e-04 -2.0906148e-03  1.7474452e-04\n",
      "  1.7439579e-03 -1.2666560e-04  2.8046418e-03 -1.0083038e-03\n",
      "  2.8730023e-03 -2.8789132e-03  3.8023510e-03 -2.6491205e-03\n",
      " -9.1494238e-03  2.4093529e-03  1.0459394e-03 -4.6120677e-03\n",
      "  1.6326011e-03 -2.9001390e-03  3.5816079e-04 -2.8459455e-03\n",
      "  5.2289572e-03  2.1124189e-03 -6.0603663e-04 -2.2824600e-03\n",
      " -4.1601271e-04  4.1880063e-03 -5.5222790e-04  9.7019860e-04\n",
      "  6.3097542e-03 -3.7836288e-03  2.0662448e-03 -4.1568666e-03\n",
      " -3.4592720e-03 -2.3819541e-03  2.3615044e-04 -5.0616213e-03\n",
      " -4.6231085e-05 -1.4283217e-04  3.4142325e-03 -1.6170293e-03\n",
      " -6.5118228e-03  2.2214772e-03 -1.2331973e-03 -3.7014224e-03\n",
      " -2.2182050e-03  2.5130846e-03  3.6561284e-03 -9.3180605e-04\n",
      "  2.2374727e-03  6.5012247e-04  1.1421820e-03  3.1383126e-05\n",
      "  1.4478685e-03], shape=(81,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# and finally we'll look at a prediction at the first timestep\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n",
    "# and of course its 65 values representing the probabillity of each character occuring next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"}gtBJVRPS.--9(3ryyWA$U1,R'jyOuASMfEJyfLtJDJEA(NyG*A6iWa?URPNWR;,Y}a-acg]!“ITHCzjY1HbGl'RJbxEzb(kM:Eo\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars  # and this is what the model predicted for training sequence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/6 [====>.........................] - ETA: 45s - loss: 4.3940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3b7c75509b19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(data1, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 800\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "    \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a starting string:  House:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House: Thes the fakin? Wilson: Whoud toproum? Loo moin conied sasta days. Oh, wich dnytchun. Cameron: House: Fore andy a gont geys! Ay then a dovy a fitht a dottere. It’s mannitspitaimactert. Cardnay: [guy ceo andy Rebecca rom. House: Will meor wilks voonk fitha jay wains foazont. Herewan: No jakey! Famenong you camentism but innoum the kilsow diy gother masting] [lduy. Wils ifing frithan a dizuct? Coferon: Pat the pli-trengey joom she foupes. Comyoul-an’t (twe lay Jadicue warks. Se mickene. Rabecco: [Gay bruttors heve? I’s battling. Camy: Eximedon it you bucteriny Fordice hareset. House: You ord, andictlicishat to ghe lig tod juin… whils Sicto. ,owh on Miaver wolds. Cmase: Ye, tomeroute butt cawh thays fore te furst onfavimod in a it’s lime thellioge stasin. [SV he’r for. Ctheme near his thiw r\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
